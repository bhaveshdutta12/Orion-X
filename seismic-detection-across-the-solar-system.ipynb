{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ab5d9e",
   "metadata": {
    "papermill": {
     "duration": 0.011223,
     "end_time": "2024-10-02T11:53:19.823092",
     "exception": false,
     "start_time": "2024-10-02T11:53:19.811869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Welcome to our NASA Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc08c91",
   "metadata": {
    "papermill": {
     "duration": 0.011057,
     "end_time": "2024-10-02T11:53:19.845289",
     "exception": false,
     "start_time": "2024-10-02T11:53:19.834232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seismic Detection Across The Solar System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb6834",
   "metadata": {
    "papermill": {
     "duration": 0.009958,
     "end_time": "2024-10-02T11:53:19.865387",
     "exception": false,
     "start_time": "2024-10-02T11:53:19.855429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ObsPy: A powerful library for reading and processing seismic data, especially .miniseed files.\n",
    "### NumPy and Pandas: For handling data and doing calculations.\n",
    "### Matplotlib and Seaborn: For plotting your results, such as the seismic waveforms and spectrograms.\n",
    "### Sklearn : For Label Encoding, Train_Test_split, Random_Forest and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8fcf38",
   "metadata": {
    "papermill": {
     "duration": 0.009956,
     "end_time": "2024-10-02T11:53:19.885605",
     "exception": false,
     "start_time": "2024-10-02T11:53:19.875649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e783ca3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T11:53:19.907690Z",
     "iopub.status.busy": "2024-10-02T11:53:19.907274Z",
     "iopub.status.idle": "2024-10-02T11:53:22.841287Z",
     "shell.execute_reply": "2024-10-02T11:53:22.840008Z"
    },
    "papermill": {
     "duration": 2.947234,
     "end_time": "2024-10-02T11:53:22.843077",
     "exception": true,
     "start_time": "2024-10-02T11:53:19.895843",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'obspy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score, confusion_matrix\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobspy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrigger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classic_sta_lta\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'obspy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import os\n",
    "from obspy.signal.trigger import classic_sta_lta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f2d50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read The CSV File into DataFrame \n",
    "lunar = pd.read_csv(\"apollo12_catalog_GradeA_final.csv\")\n",
    "lunar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f67be8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lunar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178ff086",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'time_abs(%Y-%m-%dT%H:%M:%S.%f)' to pandas datetime format\n",
    "lunar['time_abs(%Y-%m-%dT%H:%M:%S.%f)'] = pd.to_datetime(lunar['time_abs(%Y-%m-%dT%H:%M:%S.%f)'])\n",
    "\n",
    "lunar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621fc28",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of quake types\n",
    "lunar['mq_type'].value_counts().plot(kind='bar', title=\"Distribution of Quake Types\", figsize=(10, 6))\n",
    "plt.xlabel(\"Quake Type\")\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54461b3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# First Solution [Logistic Regression & Random Forest Machine Learning Models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68266dfa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Engineering: Extract hour, day, month, etc., from Abs_Time\n",
    "lunar['Hour'] = lunar['time_abs(%Y-%m-%dT%H:%M:%S.%f)'].dt.hour\n",
    "lunar['Day'] = lunar['time_abs(%Y-%m-%dT%H:%M:%S.%f)'].dt.day\n",
    "lunar['Month'] = lunar['time_abs(%Y-%m-%dT%H:%M:%S.%f)'].dt.month\n",
    "lunar['Year'] = lunar['time_abs(%Y-%m-%dT%H:%M:%S.%f)'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118dcf7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the 'filename' as numeric using LabelEncoder\n",
    "file_name_encoder = LabelEncoder()\n",
    "lunar['File_Name_Encoded'] = file_name_encoder.fit_transform(lunar['filename'])\n",
    "\n",
    "# Encode the target variable 'mq_type' as numeric\n",
    "quake_type_encoder = LabelEncoder()\n",
    "lunar['MQ_Type_Encoded'] = quake_type_encoder.fit_transform(lunar['mq_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a78aaa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lunar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f7c87",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lunar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084e37c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop columns that won't be used for classification (Abs_Time, File Name of Event, etc.)\n",
    "features = lunar.drop(columns=['time_abs(%Y-%m-%dT%H:%M:%S.%f)', 'filename', 'mq_type', 'MQ_Type_Encoded', 'evid'])\n",
    "\n",
    "# Define the target variable\n",
    "target = lunar['MQ_Type_Encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d37986",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the data to ensure it is ready for modeling\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102b847",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "logreg = LogisticRegression(random_state = 42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_lr = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest\")\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred_rf):.2f}%\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_rf)}\")\n",
    "print(f\"Confusion Matrix\\n{confusion_matrix(y_test, y_pred_rf)}\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred_lr):.2f}%\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_lr)}\")\n",
    "print(f\"Confusion Matrix\\n{confusion_matrix(y_test, y_pred_lr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45573a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_data = X_test.iloc[0:5]\n",
    "\n",
    "# Predict the Quake_Type\n",
    "predicted_quake_type_rf = rf_model.predict(new_data)\n",
    "predicted_quake_type_lr = logreg.predict(new_data)\n",
    "\n",
    "# Decode the predicted labels back to their original quake type names\n",
    "predicted_quake_type_labels = quake_type_encoder.inverse_transform(predicted_quake_type_rf)\n",
    "print(predicted_quake_type_labels)\n",
    "\n",
    "# Decode the predicted labels back to their original quake type names\n",
    "predicted_quake_type_labels = quake_type_encoder.inverse_transform(predicted_quake_type_lr)\n",
    "print(predicted_quake_type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80411333",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a confusion matrix to visualize the predictions\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=quake_type_encoder.classes_, yticklabels=quake_type_encoder.classes_)\n",
    "plt.title('Confusion Matrix [Random Forest]')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046ce3e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a confusion matrix to visualize the predictions for Logistic Regression\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=quake_type_encoder.classes_, yticklabels=quake_type_encoder.classes_)\n",
    "plt.title('Confusion Matrix [Logistic Regression]')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438cb47",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Second Solution [Applying STA/LTA Algorithm (Apply a Threshold) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58f7f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the seismic signal (using Rel_Time as an example)\n",
    "signal = lunar['time_rel(sec)'].values\n",
    "\n",
    "# Define the STA/LTA function\n",
    "def sta_lta(signal, sta_len, lta_len):\n",
    "    sta = np.convolve(signal, np.ones(sta_len) / sta_len, mode='same')\n",
    "    lta = np.convolve(signal, np.ones(lta_len) / lta_len, mode='same')\n",
    "    lta[lta == 0] = np.nan\n",
    "    sta_lta_ratio = sta / lta\n",
    "    return sta, lta, sta_lta_ratio\n",
    "\n",
    "# Set lengths for STA and LTA\n",
    "sta_length = 5\n",
    "lta_length = 50\n",
    "\n",
    "# Calculate STA, LTA, and STA/LTA ratio\n",
    "sta, lta, sta_lta_ratio = sta_lta(signal, sta_length, lta_length)\n",
    "\n",
    "# Define a threshold for detection\n",
    "threshold = 1.5\n",
    "detected_events = sta_lta_ratio > threshold\n",
    "\n",
    "# Print and save detected event times\n",
    "event_times = lunar['time_abs(%Y-%m-%dT%H:%M:%S.%f)'][detected_events]\n",
    "event_times_rel = lunar['time_rel(sec)'][detected_events]\n",
    "event_files = lunar[\"filename\"][detected_events]\n",
    "\n",
    "# Create DataFrame for detected events\n",
    "df_events = pd.DataFrame({\n",
    "    \"File_Name\": event_files,\n",
    "    \"Abs_Time\": event_times,\n",
    "    \"Rel_Time\": event_times_rel,\n",
    "    \"STA\": sta[detected_events],\n",
    "    \"LTA\": lta[detected_events],\n",
    "    \"STA/LTA Ratio\": sta_lta_ratio[detected_events]\n",
    "})\n",
    "\n",
    "# Save STA/LTA data to CSV\n",
    "output_file = 'detected_events_sta_lta.csv'\n",
    "df_events.to_csv(output_file, index=False)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(sta_lta_ratio, label='STA/LTA Ratio', color='blue')\n",
    "plt.axhline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.scatter(np.arange(len(sta_lta_ratio))[detected_events], sta_lta_ratio[detected_events], color='green', label='Detected Events')\n",
    "plt.title('STA/LTA Ratio and Detected Events')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('STA/LTA Ratio')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved STA/LTA data to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3bd9d8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sta_lta(signal, sta_len, lta_len):\n",
    "    # Calculate short-term average (STA)\n",
    "    sta = np.convolve(signal, np.ones(sta_len) / sta_len, mode='same')\n",
    "\n",
    "    # Calculate long-term average (LTA)\n",
    "    lta = np.convolve(signal, np.ones(lta_len) / lta_len, mode='same')\n",
    "\n",
    "    # Ensure both STA and LTA have the same length by using the shorter one\n",
    "    min_len = min(len(sta), len(lta))\n",
    "    sta = sta[:min_len]\n",
    "    lta = lta[:min_len]\n",
    "    \n",
    "    # Avoid division by zero in LTA\n",
    "    lta[lta == 0] = np.nan\n",
    "    \n",
    "    # Calculate STA/LTA ratio\n",
    "    sta_lta_ratio = sta / lta\n",
    "    \n",
    "    return sta, lta, sta_lta_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f4073",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sta_length in sta_lengths:\n",
    "    for lta_length in lta_lengths:\n",
    "        for threshold in thresholds:\n",
    "            # Calculate STA/LTA\n",
    "            sta, lta, sta_lta_ratio = sta_lta(signal, sta_length, lta_length)\n",
    "            \n",
    "            # Detect events\n",
    "            detected_events = sta_lta_ratio > threshold\n",
    "            event_times = lunar['time_abs(%Y-%m-%dT%H:%M:%S.%f)'][detected_events]\n",
    "            event_files = lunar[\"filename\"][detected_events]\n",
    "            event_times_rel = lunar['time_rel(sec)'][detected_events]\n",
    "\n",
    "            # Create DataFrame for detected events\n",
    "            df_events = pd.DataFrame({\n",
    "                \"File_Name\": event_files,\n",
    "                \"Abs_Time\": event_times,\n",
    "                \"Rel_Time\": event_times_rel\n",
    "            })\n",
    "\n",
    "            # Match detected events with ground truth\n",
    "            TP, FP, FN = match_events(ground_truth, df_events, pd.Timedelta(seconds=10))\n",
    "            \n",
    "            # Calculate accuracy metrics\n",
    "            accuracy = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
    "            precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "            recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "            # Check if this configuration is the best so far\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {\n",
    "                    'sta_length': sta_length,\n",
    "                    'lta_length': lta_length,\n",
    "                    'threshold': threshold,\n",
    "                    'accuracy': accuracy,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1_score': f1_score\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4523af9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391607b4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the detected event times\n",
    "event_times = lunar['time_abs(%Y-%m-%dT%H:%M:%S.%f)'][detected_events]\n",
    "event_times_rel = lunar['time_rel(sec)'][detected_events]\n",
    "event_files = lunar[\"filename\"][detected_events]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"File_Name\" : event_files,\n",
    "    \"Abs_Time\" : event_times,\n",
    "    \"Rel_Time\" : event_times_rel\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28242481",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Anthor Third Solution By Machine Learning Model with [STA, LTA, STA/LTA] Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dde2a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the signal (assuming Rel_Time is a numeric signal)\n",
    "signal = lunar['time_rel(sec)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becfea72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate STA, LTA, and STA/LTA ratio\n",
    "sta_length = 5\n",
    "lta_length = 50\n",
    "sta, lta, sta_lta_ratio = sta_lta(signal, sta_length, lta_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ccee92",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add features to the DataFrame\n",
    "lunar['STA'] = sta\n",
    "lunar['LTA'] = lta\n",
    "lunar['STA/LTA'] = sta_lta_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4edec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lunar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0eddda",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lunar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467d3f4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lunar[lunar[\"STA/LTA\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ca5af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lunar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb19369",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lunar.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621fc378",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the target variable (assuming Quake_Type is your label)\n",
    "X = lunar[['STA', 'LTA', 'STA/LTA']]  # Features\n",
    "y = lunar['MQ_Type_Encoded']  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3a50d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 7: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa028ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 8: Train the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509ea22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the Model\n",
    "print(f\"Accuracy = {accuracy_score(y_test, y_pred) * 100 :.2F} %\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a4f5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the STA/LTA Ratio and Detected Events\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot STA/LTA ratio\n",
    "plt.plot(sta_lta_ratio, label='STA/LTA Ratio', color='blue')\n",
    "plt.axhline(1.5, color='red', linestyle='--', label='Threshold')  # Change threshold if needed\n",
    "\n",
    "# Highlight detected events based on the threshold\n",
    "detected_events = sta_lta_ratio > 1.5\n",
    "plt.scatter(np.arange(len(sta_lta_ratio))[detected_events], sta_lta_ratio[detected_events], color='green', label='Detected Events')\n",
    "\n",
    "plt.title('STA/LTA Ratio and Detected Events')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('STA/LTA Ratio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423edd0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4959e542",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Combine all Test Files into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d27528",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = 'D:\\\\NASA Challenge\\\\space_apps_2024_seismic_detection\\\\data\\\\lunar\\\\test\\\\data\\\\S12_GradeB\\\\'\n",
    "combined_data = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.csv'):\n",
    "        # Try reading the CSV file using engine='python'\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(directory, file), engine='python')\n",
    "            combined_data.append(df)\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error parsing {file}: {e}\")\n",
    "\n",
    "# Combine all dataframes into one\n",
    "if combined_data:\n",
    "    combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "    print(\"Successfully combined all CSV files.\")\n",
    "else:\n",
    "    print(\"No valid CSV files to combine.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737cab8e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "S12_GradeB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c469d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Test on File [S12_GradeB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7dfc6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "signal = S12_GradeB['time_rel(sec)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206ce8c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set lengths for STA and LTA\n",
    "sta_length = 5    # Short-term average window length\n",
    "lta_length = 50   # Long-term average window length\n",
    "\n",
    "# Calculate STA, LTA, and STA/LTA ratio\n",
    "sta, lta, sta_lta_ratio = sta_lta(signal, sta_length, lta_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945246a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a threshold for detection\n",
    "threshold = 1.5\n",
    "\n",
    "# Create an array for event detection based on the threshold\n",
    "detected_events = sta_lta_ratio > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2080d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the detected event times\n",
    "event_times = S12_GradeB['time_abs(%Y-%m-%dT%H:%M:%S.%f)'][detected_events]\n",
    "print(f\"Detected Events:\\n{event_times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fba33d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the detected event times\n",
    "event_times = S12_GradeB['time_abs(%Y-%m-%dT%H:%M:%S.%f)'][detected_events]\n",
    "event_times_rel = S12_GradeB['time_rel(sec)'][detected_events]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Abs_Time\" : event_times,\n",
    "    \"Rel_Time\" : event_times_rel\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b77c73",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6: Visualize the results\n",
    "plt.figure(figsize=(25, 6))\n",
    "\n",
    "# Plot STA/LTA ratio\n",
    "plt.plot(sta_lta_ratio, label='STA/LTA Ratio', color='blue')\n",
    "plt.axhline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "\n",
    "# Highlight detected events\n",
    "plt.scatter(np.arange(len(sta_lta_ratio))[detected_events], sta_lta_ratio[detected_events], color='green', label='Detected Events')\n",
    "\n",
    "plt.title('STA/LTA Ratio and Detected Events')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('STA/LTA Ratio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b63bd8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.signal.trigger import classic_sta_lta, trigger_onset\n",
    "\n",
    "def apply_sta_lta(csv_file, sta_len=120, lta_len=600, sampling_rate=100, threshold=2.0):\n",
    "    \"\"\"\n",
    "    Function to read a CSV file, apply STA/LTA, and plot the characteristic function with detected events.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file (str): Path to the CSV file.\n",
    "    sta_len (int): Length of the short-term window in seconds.\n",
    "    lta_len (int): Length of the long-term window in seconds.\n",
    "    sampling_rate (int): Sampling frequency of the data in Hz.\n",
    "    threshold (float): STA/LTA threshold for event detection.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Read the CSV file\n",
    "    data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Check if required columns are present in the CSV file\n",
    "    if 'time_rel(sec)' not in data.columns or 'velocity(m/s)' not in data.columns:\n",
    "        raise ValueError(f\"CSV file {csv_file} must contain 'time_rel(sec)' and 'velocity(m/s)' columns.\")\n",
    "    \n",
    "    # Step 2: Extract relevant columns\n",
    "    rel_time = data['time_rel(sec)'].values  # Time data (X-axis)\n",
    "    velocity = data['velocity(m/s)'].values  # Seismic amplitude or velocity (Y-axis)\n",
    "    \n",
    "    # Step 3: Calculate STA/LTA using Obspy's function\n",
    "    sta_samples = int(sta_len * sampling_rate)  # Convert seconds to samples\n",
    "    lta_samples = int(lta_len * sampling_rate)  # Convert seconds to samples\n",
    "    \n",
    "    # Apply classic STA/LTA to the velocity data\n",
    "    cft = classic_sta_lta(velocity, sta_samples, lta_samples)\n",
    "    \n",
    "    # Step 4: Detect events based on the STA/LTA characteristic function\n",
    "    onsets = trigger_onset(cft, threshold, threshold / 2)  # Get onset and end times of events\n",
    "    \n",
    "    # Step 5: Plot the characteristic function (STA/LTA ratio over time)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(rel_time, cft, label='STA/LTA Characteristic Function')\n",
    "    plt.axhline(y=threshold, color='red', linestyle='--', label='Threshold')\n",
    "    \n",
    "    # Mark detected events on the plot\n",
    "    for onset in onsets:\n",
    "        start_time = rel_time[onset[0]]\n",
    "        plt.plot(start_time, threshold, 'go', markersize=10, label='Detected Event')  # Marker for detected event\n",
    "    \n",
    "    plt.xlabel('Relative Time (s)')\n",
    "    plt.ylabel('STA/LTA Ratio')\n",
    "    plt.title('STA/LTA Characteristic Function with Detected Events')\n",
    "    plt.xlim([min(rel_time), max(rel_time)])\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = 'S12_GradeB.csv'  # Replace with the actual path to your CSV file\n",
    "apply_sta_lta(csv_file_path, sta_len=120, lta_len=600, sampling_rate=100)\n",
    "\n",
    "import os\n",
    "\n",
    "# Directory containing test CSV files\n",
    "test_dir = 'D:\\\\NASA Challenge\\\\space_apps_2024_seismic_detection\\\\data\\\\lunar\\\\test\\\\data\\\\S12_GradeB\\\\'  \n",
    "\n",
    "# Loop through each file in the directory and apply STA/LTA\n",
    "for file_name in os.listdir(test_dir):\n",
    "    file_path = os.path.join(test_dir, file_name)\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "\n",
    "    try:\n",
    "        apply_sta_lta(file_path, sta_len=120, lta_len=600, sampling_rate=100)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fc85e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.signal.trigger import classic_sta_lta, trigger_onset\n",
    "\n",
    "def apply_sta_lta(csv_file, sta_len=120, lta_len=600, sampling_rate=100, threshold=2.0):\n",
    "    \"\"\"\n",
    "    Function to read a CSV file, apply STA/LTA, detect events, and output results.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file (str): Path to the CSV file.\n",
    "    sta_len (int): Length of the short-term window in seconds.\n",
    "    lta_len (int): Length of the long-term window in seconds.\n",
    "    sampling_rate (int): Sampling frequency of the data in Hz.\n",
    "    threshold (float): STA/LTA threshold for event detection.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with detected events.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Read the CSV file\n",
    "    data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Check if required columns are present in the CSV file\n",
    "    if 'time_rel(sec)' not in data.columns or 'velocity(m/s)' not in data.columns:\n",
    "        raise ValueError(f\"CSV file {csv_file} must contain 'Rel_Time' and 'Velocity' columns.\")\n",
    "    \n",
    "    # Step 2: Extract relevant columns\n",
    "    rel_time = data['time_rel(sec)'].values  # Time data (X-axis)\n",
    "    velocity = data['velocity(m/s)'].values  # Seismic amplitude or velocity (Y-axis)\n",
    "    \n",
    "    # Step 3: Calculate STA/LTA using Obspy's function\n",
    "    sta_samples = int(sta_len * sampling_rate)  # Convert seconds to samples\n",
    "    lta_samples = int(lta_len * sampling_rate)  # Convert seconds to samples\n",
    "    \n",
    "    # Apply classic STA/LTA to the velocity data\n",
    "    cft = classic_sta_lta(velocity, sta_samples, lta_samples)\n",
    "    \n",
    "    # Step 4: Detect events based on the STA/LTA characteristic function\n",
    "    onsets = trigger_onset(cft, threshold, threshold / 2)  # Get onset and end times of events\n",
    "    \n",
    "    # Step 5: Prepare output data for detected events\n",
    "    event_data = []\n",
    "    for onset in onsets:\n",
    "        start_time = rel_time[onset[0]]\n",
    "        event_data.append({\n",
    "            'filename': csv_file,\n",
    "            'time_rel': start_time  # You can adjust this to include absolute time if available\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame for the output catalog\n",
    "    output_df = pd.DataFrame(event_data)\n",
    "    \n",
    "    # Save the output catalog to a CSV file\n",
    "    output_file = f\"detected_events_{csv_file.split('/')[-1].replace('.csv', '')}.csv\"\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Plotting characteristic function and detected events\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(rel_time, cft, label='STA/LTA Characteristic Function')\n",
    "    plt.axhline(y=threshold, color='red', linestyle='--', label='Threshold')\n",
    "    \n",
    "    # Mark detected events on the plot\n",
    "    for onset in onsets:\n",
    "        start_time = rel_time[onset[0]]\n",
    "        plt.plot(start_time, threshold, 'go', markersize=10)  # Marker for detected event\n",
    "    \n",
    "    plt.xlabel('Relative Time (s)')\n",
    "    plt.ylabel('STA/LTA Ratio')\n",
    "    plt.title('STA/LTA Characteristic Function with Detected Events')\n",
    "    plt.xlim([min(rel_time), max(rel_time)])\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return output_df  # Return the DataFrame for further use if needed\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = 'S12_gradeB.csv'  # Replace with the actual path to your CSV file\n",
    "output_df = apply_sta_lta(csv_file_path, sta_len=120, lta_len=600, sampling_rate=100, threshold=2.0)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc919205",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from obspy.signal.trigger import classic_sta_lta, trigger_onset\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def highpass_filter(data, cutoff, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "def apply_sta_lta(csv_file, sta_len=120, lta_len=600, sampling_rate=100, threshold=2.0):\n",
    "    # Step 1: Read the CSV file\n",
    "    data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Step 2: Extract relevant columns\n",
    "    rel_time = data['time_rel(sec)'].values  # Time data (X-axis)\n",
    "    velocity = data['velocity(m/s)'].values  # Seismic amplitude or velocity (Y-axis)\n",
    "    \n",
    "    # Step 3: Preprocess the data (highpass filtering)\n",
    "    velocity_filtered = highpass_filter(velocity, cutoff=1.0, fs=sampling_rate)\n",
    "    \n",
    "    # Step 4: Calculate STA/LTA\n",
    "    sta_samples = int(sta_len * sampling_rate)\n",
    "    lta_samples = int(lta_len * sampling_rate)\n",
    "    cft = classic_sta_lta(velocity_filtered, sta_samples, lta_samples)\n",
    "    \n",
    "    # Step 5: Detect events based on threshold\n",
    "    onsets = trigger_onset(cft, threshold, threshold / 2)\n",
    "    \n",
    "    # Step 6: Plot the STA/LTA function\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(rel_time, cft, label='STA/LTA Characteristic Function')\n",
    "    plt.axhline(threshold, color='r', linestyle='--', label='Threshold')\n",
    "    \n",
    "    # Mark detected quake events\n",
    "    for onset in onsets:\n",
    "        plt.axvline(rel_time[onset[0]], color='g', linestyle='--', label='Quake Detected')\n",
    "    \n",
    "    plt.xlabel('Relative Time (s)')\n",
    "    plt.ylabel('STA/LTA Ratio')\n",
    "    plt.title('STA/LTA Characteristic Function with Quake Detection')\n",
    "    plt.xlim([min(rel_time), max(rel_time)])\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = 'S12_GradeB.csv'  # Replace with actual CSV path\n",
    "apply_sta_lta(csv_file_path, sta_len=120, lta_len=600, sampling_rate=100, threshold=2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc39be8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Test on Mars Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629f45",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the directory where the CSV files are located\n",
    "directory = 'D:\\\\NASA Challenge\\\\space_apps_2024_seismic_detection\\\\data\\\\mars\\\\test\\\\data\\\\'\n",
    "\n",
    "# Create an empty list to hold the dataframes\n",
    "combined_data = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.csv'):\n",
    "        # Read each CSV file\n",
    "        df = pd.read_csv(os.path.join(directory, file))\n",
    "        combined_data.append(df)\n",
    "\n",
    "# Combine all dataframes into one\n",
    "Mars = pd.concat(combined_data, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "Mars.to_csv('Mars Test.csv', index=False)\n",
    "\n",
    "print(\"Files combined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7b13d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Mars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03973b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Mars[\"velocity(m/s)\"] = Mars[\"velocity(c/s)\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9f950",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Mars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98102b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the signal (assuming Rel_Time is a numeric signal)\n",
    "signal = Mars['rel_time(sec)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725fcbb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set lengths for STA and LTA\n",
    "sta_length = 5    # Short-term average window length\n",
    "lta_length = 50   # Long-term average window length\n",
    "\n",
    "# Calculate STA, LTA, and STA/LTA ratio\n",
    "sta, lta, sta_lta_ratio = sta_lta(signal, sta_length, lta_length)\n",
    "\n",
    "# Define a threshold for detection\n",
    "threshold = 1.5\n",
    "\n",
    "# Create an array for event detection based on the threshold\n",
    "detected_events = sta_lta_ratio > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e9b6c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the detected event times\n",
    "event_times = Mars['time(%Y-%m-%dT%H:%M:%S.%f)'][detected_events]\n",
    "print(f\"Detected Events:\\n{event_times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6491c03",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the detected event times\n",
    "event_times = Mars['time(%Y-%m-%dT%H:%M:%S.%f)'][detected_events]\n",
    "event_times_rel = Mars['rel_time(sec)'][detected_events]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Abs_Time\" : event_times,\n",
    "    \"Rel_Time\" : event_times_rel\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae404b0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot STA/LTA ratio\n",
    "plt.plot(sta_lta_ratio, label='STA/LTA Ratio', color='blue')\n",
    "plt.axhline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "\n",
    "# Highlight detected events\n",
    "plt.scatter(np.arange(len(sta_lta_ratio))[detected_events], sta_lta_ratio[detected_events], color='green', label='Detected Events')\n",
    "\n",
    "plt.title('STA/LTA Ratio and Detected Events')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('STA/LTA Ratio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.276908,
   "end_time": "2024-10-02T11:53:23.473923",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-02T11:53:17.197015",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
